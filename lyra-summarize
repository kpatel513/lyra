#!/bin/bash

# Lyra Repository Analysis Script
# Usage: lyra-summarize REPO_PATH [TRAINING_SCRIPT]

if [ $# -eq 0 ]; then
    echo "Usage: lyra-summarize REPO_PATH [TRAINING_SCRIPT]"
    echo ""
    echo "Arguments:"
    echo "  REPO_PATH        Path to the ML repository"
    echo "  TRAINING_SCRIPT  Optional: Specific training script to analyze (e.g., train.py, src/fine_tune.py)"
    echo ""
    echo "Examples:"
    echo "  lyra-summarize ~/my-project                           # Analyze entire repository"
    echo "  lyra-summarize ~/my-project train.py                 # Focus on specific script"
    echo "  lyra-summarize ~/my-project src/models/fine_tune.py  # Focus on script in subdirectory"
    exit 1
fi

REPO_PATH="$1"
TRAINING_SCRIPT="${2:-}"

# Validate repository path
if [ ! -d "$REPO_PATH" ]; then
    echo "‚ùå Error: Directory $REPO_PATH does not exist"
    exit 1
fi

if [ ! -r "$REPO_PATH" ]; then
    echo "‚ùå Error: Directory $REPO_PATH is not readable"
    exit 1
fi

# If training script is specified, validate it exists
if [ -n "$TRAINING_SCRIPT" ]; then
    FULL_SCRIPT_PATH="$REPO_PATH/$TRAINING_SCRIPT"
    if [ ! -f "$FULL_SCRIPT_PATH" ]; then
        echo "‚ùå Error: Training script $TRAINING_SCRIPT does not exist in $REPO_PATH"
        exit 1
    fi
fi

# Convert to absolute path
REPO_PATH="$(cd "$REPO_PATH" && pwd)"

# Lyra will use a temporary file for the prompt to avoid shell escaping issues

# Display progress information
echo "üéº Lyra Repository Analysis Starting..."
echo "üìÇ Repository: $REPO_PATH"
if [ -n "$TRAINING_SCRIPT" ]; then
    echo "üéØ Target Script: $TRAINING_SCRIPT"
else
    echo "üîç Mode: Full repository analysis"
fi
echo ""
echo "üéµ Initializing Lyra's harmonic analysis..."
echo "‚≠ê Searching for mixed precision training implementations..."
echo "üåü Analyzing distributed training and sharding patterns..."
echo "üé∂ Weaving together the musical threads of your codebase..."
echo ""
echo "üé≠ Please wait while Orpheus performs his code analysis symphony..."
echo "   This may take 1-3 minutes depending on repository size..."
echo ""

# Run Claude Code with the prompt using a temporary file to avoid shell escaping issues
TEMP_PROMPT_FILE=$(mktemp)

# Add dynamic content based on training script parameter
if [ -n "$TRAINING_SCRIPT" ]; then
    TARGET_INFO="üéØ **Target Training Script**: $TRAINING_SCRIPT"
    FOCUS_AREAS="üéº **Analysis Scope**: Focus primarily on the specified training script: $TRAINING_SCRIPT 

‚ö†Ô∏è  **CRITICAL**: Analyze the TARGET SCRIPT ($TRAINING_SCRIPT) specifically for mixed precision and sharding usage. Do NOT assume the entire repository uses these features if the target script does not. Base conclusions on what is actually implemented in the specified file and its direct imports/dependencies.

If the target script uses FP32/float32 without mixed precision configurations, the answer for mixed precision should be NO, regardless of what other files in the repository might contain."
else
    TARGET_INFO="üîç **Full Repository Mode**: Analyzing all training components"
    FOCUS_AREAS=""
fi

cat > "$TEMP_PROMPT_FILE" << 'EOF'
üéµ Welcome to Lyra - Your AI-powered repository harmonizer! üéµ

Like Orpheus with his lyre, I shall weave through your codebase to create a melodious analysis ‚ú®

üéº **Analysis Symphony - Movement I: Mixed Precision Training** üéº
Search for evidence of mixed precision training usage, including:
   ‚≠ê Automatic Mixed Precision (AMP) implementations
   ‚≠ê FP16/BF16 data types usage
   ‚≠ê GradScaler usage
   ‚≠ê Mixed precision configuration files
   ‚≠ê Training scripts with precision settings

üé∂ **Analysis Symphony - Movement II: Sharding & Distribution** üé∂
Discover the harmonic patterns of distributed training and model/data sharding:
   üåü Data parallel training setups
   üåü Model parallelism configurations
   üåü Tensor sharding strategies
   üåü Distributed training frameworks (DeepSpeed, FairScale, etc.)
   üåü Pipeline parallelism implementations

üéº For each celestial finding, please provide:
üéµ File locations with line numbers
üéµ Brief code snippets showing the implementation
üéµ Configuration details if available
üéµ Framework/library used (PyTorch, TensorFlow, JAX, etc.)

üé≠ **REQUIRED OUTPUT FORMAT**:

## Mixed Precision Training: [YES/NO]
[Detailed analysis with specific evidence]
- File locations and line numbers where found (or state "NOT FOUND")
- Code snippets showing implementation (or explain what was found instead)
- Specific precision types detected (FP32, FP16, BF16, etc.)

## Sharding/Distribution: [YES/NO] 
[Detailed analysis with specific evidence]
- File locations and line numbers where found (or state "NOT FOUND")
- Code snippets showing implementation (or explain what was found instead)
- Specific frameworks/strategies detected

**CRITICAL**: Base conclusions ONLY on actual code evidence. If you find FP32/float32 usage without mixed precision setup, clearly state "Mixed Precision Training: NO" and explain what precision is actually being used. Be thorough and precise - this analysis guides optimization decisions! üéº‚ú®
EOF

# Add the dynamic content to the prompt file
echo "" >> "$TEMP_PROMPT_FILE"
echo "$TARGET_INFO" >> "$TEMP_PROMPT_FILE"
if [ -n "$FOCUS_AREAS" ]; then
    echo "" >> "$TEMP_PROMPT_FILE"
    echo "$FOCUS_AREAS" >> "$TEMP_PROMPT_FILE"
fi

if cd "$REPO_PATH" && claude --print "$(cat "$TEMP_PROMPT_FILE")"; then
    rm -f "$TEMP_PROMPT_FILE"
    # Display completion message
    echo ""
    echo "üéº‚ú® Analysis complete! The harmonious report has been generated above."
else
    rm -f "$TEMP_PROMPT_FILE"
    echo ""
    echo "‚ùå Error: Claude Code analysis failed. This could be due to:"
    echo "   ‚Ä¢ Claude Code authentication issues"
    echo "   ‚Ä¢ Network connectivity problems"
    echo "   ‚Ä¢ Repository size or complexity"
    echo "   ‚Ä¢ Insufficient permissions"
    echo ""
    echo "üîß Troubleshooting suggestions:"
    echo "   1. Check Claude Code authentication: claude config"
    echo "   2. Try with a smaller test repository"
    echo "   3. Ensure stable internet connection"
    echo "   4. Check repository permissions"
    exit 1
fi